{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conversation' from 'c:\\\\Projects\\\\sara\\\\conversation.py'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import conversation\n",
    "import importlib\n",
    "importlib.reload(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up conversation 5\n"
     ]
    }
   ],
   "source": [
    "conversation1 = conversation.Conversation(\"./conversations\", load=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_path = conversation1.textToSpeech(question = conversation1.question_storage[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation1.speak(q1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please speak something...\n",
      "Recognizing...\n",
      "Audio saved to captured_audio.wav\n"
     ]
    }
   ],
   "source": [
    "a1_audio = conversation1.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\sara\\prototype2.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/sara/prototype2.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a1_text \u001b[39m=\u001b[39m conversation1\u001b[39m.\u001b[39;49mspeechToText(a1_audio)\n",
      "File \u001b[1;32mc:\\Projects\\sara\\conversation.py:117\u001b[0m, in \u001b[0;36mConversation.speechToText\u001b[1;34m(self, audioData)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspeechToText\u001b[39m(\u001b[39mself\u001b[39m, audioData: sr\u001b[39m.\u001b[39mAudioData) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    115\u001b[0m     \u001b[39m# Recieves audio data object and returns a transcript\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[39m# Saves transcript to transcript_storage\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecognizer\u001b[39m.\u001b[39;49mrecognize_google(audioData)\n\u001b[0;32m    118\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou said: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranscript_storage\u001b[39m.\u001b[39mappend(text)\n",
      "File \u001b[1;32mc:\\Projects\\sara\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:728\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mif\u001b[39;00m show_all:\n\u001b[0;32m    726\u001b[0m     \u001b[39mreturn\u001b[39;00m actual_result\n\u001b[1;32m--> 728\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(actual_result, \u001b[39mdict\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(actual_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m, [])) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    731\u001b[0m     \u001b[39m# return alternative with highest confidence score\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     best_hypothesis \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(actual_result[\u001b[39m\"\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m\"\u001b[39m], key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m alternative: alternative[\u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a1_text = conversation1.speechToText(a1_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_text = \"This is an example answer text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = conversation1.summarize(a1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an example answer text.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, that sounds interesting! Could you tell me more about how you felt when you first met your first love?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.generateQuestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How did you meet your first love?',\n",
       " 'Oh, that sounds interesting! Could you tell me more about how you felt when you first met your first love?']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.question_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is an example answer text.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation1.summary_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_path = conversation1.textToSpeech(question = conversation1.question_storage[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation1.speak(q2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "0: How did you meet your first love?\n",
      "1: Oh, that sounds interesting! Could you tell me more about how you felt when you first met your first love?\n",
      "----------\n",
      "Summaries:\n",
      "0: This is an example answer text.\n"
     ]
    }
   ],
   "source": [
    "conversation1.showHistory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
